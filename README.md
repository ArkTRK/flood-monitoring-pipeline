# ğŸŒŠ Smart Flood Monitoring Pipeline (ETL + AI)

Este projeto Ã© um pipeline de dados **ETL (Extract, Transform, Load)** desenvolvido para monitorar riscos de enchentes em tempo real. O sistema extrai dados meteorolÃ³gicos de alta precisÃ£o, utiliza InteligÃªncia Artificial para analisar o contexto geogrÃ¡fico e armazena insights estruturados em um banco de dados PostgreSQL.

## ğŸš€ Funcionalidades

- **ExtraÃ§Ã£o DinÃ¢mica:** Consome dados da API Open-Meteo para cidades cadastradas em um banco de dados relacional.
- **AnÃ¡lise HistÃ³rica e Preditiva:** Calcula o acumulado de chuva das Ãºltimas 24h (saturaÃ§Ã£o do solo) e a previsÃ£o para as prÃ³ximas 3h.
- **InteligÃªncia Artificial:** IntegraÃ§Ã£o com **Google Gemini AI** para gerar alertas humanizados e nÃ­veis de risco (Baixo, Moderado, Alto, CrÃ­tico).
- **PersistÃªncia de Dados:** Armazena o histÃ³rico tÃ©cnico e os insights da IA para futuras anÃ¡lises de dados.

## ğŸ› ï¸ Tecnologias Utilizadas

- **Linguagem:** Python 3.11+
- **Banco de Dados:** PostgreSQL
- **IA:** Google Gemini API (`gemini-2.5-flash-lite`)
- **APIs de Clima:** Open-Meteo
- **Bibliotecas Principais:** `psycopg2`, `pandas`, `google-generativeai`, `requests-cache`

## ğŸ“‹ PrÃ©-requisitos

Antes de iniciar, vocÃª precisarÃ¡ ter:
- Um servidor PostgreSQL ativo.
- Uma chave de API do Google Gemini.
- Python instalado no seu ambiente (Ubuntu/Windows).

## ğŸ”§ ConfiguraÃ§Ã£o

1. **Clone o repositÃ³rio:**
   
   git clone [https://github.com/seu-usuario/seu-repositorio.git](https://github.com/seu-usuario/seu-repositorio.git)
   cd seu-repositorio

2. **Instale as dependÃªncias**
   
   pip install -r requirements.txt
  
3. **Configure as VariÃ¡veis de Ambiente**
Crie um arquivo .env baseado no exemplo abaixo:

DB_HOST=seu_ip
DB_NAME=weather_db
DB_USER=seu_usuario
DB_PASS=sua_senha
DB_PORT=5432
GEMINI_API_KEY=sua_chave_aqui

4. **Prepare o Banco de Dados**
Execute os scripts SQL disponÃ­veis em schema.sql para criar as tabelas cidades, historico_clima e insights_gemini.

**Exemplo de SaÃ­da**
ğŸ“ Processando: RIO DE JANEIRO
   ğŸ“Š Dados Brutos: Acumulado 24h: 45.20mm | PrevisÃ£o 3h: 12.50mm

   ğŸ¤– ANÃLISE DO GEMINI:
      â— Risco: Alto
      â— Alerta: Risco iminente de alagamentos em Ã¡reas de encosta e regiÃµes baixas.
      â— AÃ§Ã£o: Evite Ã¡reas com histÃ³rico de inundaÃ§Ã£o e atente para os sinais de alerta da Defesa Civil.

   ğŸ’¾ Dados persistidos no PostgreSQL.

## ğŸ—ï¸ Infraestrutura e ExecuÃ§Ã£o

O projeto foi desenvolvido e testado utilizando a seguinte infraestrutura:

### Minha Stack Atual
* **Servidor:** Ubuntu Server (ExecuÃ§Ã£o do script Python e hospedagem do banco).
* **Banco de Dados:** PostgreSQL (InstÃ¢ncia local no servidor).

### SugestÃµes de EvoluÃ§Ã£o (Cloud)
Para cenÃ¡rios de alta disponibilidade e escala, o projeto pode ser migrado para:
* **AWS:** AWS Lambda para execuÃ§Ã£o do script (Serverless) + Amazon RDS para o PostgreSQL.
* **Google Cloud:** Cloud Functions + Cloud SQL.
* **Docker:** ContainerizaÃ§Ã£o da aplicaÃ§Ã£o para facilitar o deploy em qualquer ambiente (incluÃ­do `Dockerfile` como melhoria futura).

## ğŸ› ï¸ ExecuÃ§Ã£o no Ambiente de Desenvolvimento

Para validar o pipeline e visualizar os alertas em tempo real:
1. Abra o projeto no **VS Code**.
2. Certifique-se de que o banco PostgreSQL estÃ¡ rodando no seu servidor ou localhost.
3. Execute o script principal:
   ```bash
   python main.py
